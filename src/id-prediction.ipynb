{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bittoolsvirtualenvc4ff698609d54025b7f78dd67478b0a8",
   "display_name": "Python 3.7.5 64-bit ('tools': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\tools\\miniconda3\\lib\\site-packages\\h5py\\__init__.py:75: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems\n  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import finetune_resnet\n",
    "import h5py\n",
    "from keras.metrics import sparse_categorical_accuracy\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = h5py.File(\"../Market-1501/market.h5\")\n",
    "x = dataset[\"train_images\"]\n",
    "attributes_target = dataset[\"train_labels\"]\n",
    "file_names = dataset[\"train_images_files\"]\n",
    "ids_encoder = dict()\n",
    "train_ids = np.zeros(len(file_names), dtype=int)\n",
    "i = 0\n",
    "for j, file in enumerate(file_names):\n",
    "    if file[:4] not in ids_encoder:\n",
    "        ids_encoder[file[:4]] = i\n",
    "        i += 1\n",
    "    train_ids[j] = ids_encoder[file[:4]]\n",
    "n_id = len(ids_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((12567,), 751)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids.shape, n_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
    }
   ],
   "source": [
    "_, training_model, inference_model = finetune_resnet.get_models(n_person=n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 128, 64, 3)   0                                            \n__________________________________________________________________________________________________\nresnet50 (Model)                (None, 2048)         23587712    input_1[0][0]                    \n__________________________________________________________________________________________________\nattributes (Dense)              (None, 27)           55323       resnet50[1][0]                   \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 512)          1049088     resnet50[1][0]                   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 27)           756         attributes[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 27)           0           attributes[0][0]                 \n                                                                 dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nimage_features (Concatenate)    (None, 539)          0           multiply_1[0][0]                 \n                                                                 dropout_1[0][0]                  \n__________________________________________________________________________________________________\nids (Dense)                     (None, 751)          405540      image_features[0][0]             \n==================================================================================================\nTotal params: 25,100,467\nTrainable params: 25,046,323\nNon-trainable params: 54,144\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "# sparse_top_k_categorical_accuracy\n",
    "# TODO: rename layers\n",
    "training_model.compile(\"adam\", loss=[\"binary_crossentropy\", \"sparse_categorical_crossentropy\"], metrics={\"attributes\":[finetune_resnet.market_attribute_accuracy], \"ids\":[sparse_categorical_accuracy]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((1, 27), (1, 751))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes, categorical_id = training_model.predict(finetune_resnet.preprocess_images(x[:1]))\n",
    "attributes.shape, categorical_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 539)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_embedding = inference_model.predict(finetune_resnet.preprocess_images(x[:1]))\n",
    "id_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nTrain on 320 samples, validate on 80 samples\nEpoch 1/5\n320/320 [==============================] - 161s 504ms/step - loss: 5.1528 - attributes_loss: 0.4250 - ids_loss: 4.7278 - attributes_market_attribute_accuracy: 0.7157 - ids_sparse_categorical_accuracy: 0.3188 - val_loss: 8.9609 - val_attributes_loss: 0.6108 - val_ids_loss: 8.3501 - val_attributes_market_attribute_accuracy: 0.6235 - val_ids_sparse_categorical_accuracy: 0.0000e+00\nEpoch 2/5\n320/320 [==============================] - 78s 243ms/step - loss: 1.1767 - attributes_loss: 0.1777 - ids_loss: 0.9989 - attributes_market_attribute_accuracy: 0.8780 - ids_sparse_categorical_accuracy: 0.8375 - val_loss: 8.3489 - val_attributes_loss: 0.4875 - val_ids_loss: 7.8615 - val_attributes_market_attribute_accuracy: 0.6648 - val_ids_sparse_categorical_accuracy: 0.0000e+00\nEpoch 3/5\n320/320 [==============================] - 68s 212ms/step - loss: 0.3717 - attributes_loss: 0.0925 - ids_loss: 0.2792 - attributes_market_attribute_accuracy: 0.9481 - ids_sparse_categorical_accuracy: 0.9375 - val_loss: 8.4287 - val_attributes_loss: 0.4583 - val_ids_loss: 7.9704 - val_attributes_market_attribute_accuracy: 0.6753 - val_ids_sparse_categorical_accuracy: 0.0000e+00\nEpoch 4/5\n320/320 [==============================] - 60s 187ms/step - loss: 0.1464 - attributes_loss: 0.0411 - ids_loss: 0.1053 - attributes_market_attribute_accuracy: 0.9864 - ids_sparse_categorical_accuracy: 0.9844 - val_loss: 8.9256 - val_attributes_loss: 0.4167 - val_ids_loss: 8.5089 - val_attributes_market_attribute_accuracy: 0.6857 - val_ids_sparse_categorical_accuracy: 0.0125\nEpoch 5/5\n320/320 [==============================] - 71s 223ms/step - loss: 0.0569 - attributes_loss: 0.0236 - ids_loss: 0.0332 - attributes_market_attribute_accuracy: 0.9934 - ids_sparse_categorical_accuracy: 0.9875 - val_loss: 9.4732 - val_attributes_loss: 0.4416 - val_ids_loss: 9.0316 - val_attributes_market_attribute_accuracy: 0.6978 - val_ids_sparse_categorical_accuracy: 0.0125\n"
    }
   ],
   "source": [
    "cb = [\n",
    "    ModelCheckpoint(\"../models/full-model-test-0.h5\")\n",
    "]\n",
    "\n",
    "n_samples = 400\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "history = training_model.fit(\n",
    "    x=finetune_resnet.preprocess_images(np.array(x[:n_samples])),\n",
    "    y=[finetune_resnet.preprocess_labels(np.array(attributes_target[:n_samples])), train_ids[:n_samples]],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=cb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'val_loss': [8.960886764526368,\n  8.34894905090332,\n  8.428741073608398,\n  8.925591278076173,\n  9.473195648193359],\n 'val_attributes_loss': [0.6108266234397888,\n  0.4874896168708801,\n  0.4583412766456604,\n  0.4167355537414551,\n  0.44159516096115115],\n 'val_ids_loss': [8.350060081481933,\n  7.861459159851075,\n  7.970399856567383,\n  8.508855628967286,\n  9.03160057067871],\n 'val_attributes_market_attribute_accuracy': [0.6235227584838867,\n  0.6647727727890015,\n  0.6753409624099731,\n  0.6856818199157715,\n  0.6978409767150879],\n 'val_ids_sparse_categorical_accuracy': [0.0, 0.0, 0.0, 0.0125, 0.0125],\n 'loss': [5.15276882648468,\n  1.176661390066147,\n  0.3717037051916122,\n  0.1464253045618534,\n  0.056865626201033595],\n 'attributes_loss': [0.4249697357416153,\n  0.1777344048023224,\n  0.09251592755317688,\n  0.0410867303609848,\n  0.02362410519272089],\n 'ids_loss': [4.727799129486084,\n  0.9989269793033599,\n  0.2791877768933773,\n  0.10533857569098473,\n  0.03324152128770948],\n 'attributes_market_attribute_accuracy': [0.7156534314155578,\n  0.8779830276966095,\n  0.9480966746807098,\n  0.9863921344280243,\n  0.9934091925621032],\n 'ids_sparse_categorical_accuracy': [0.31875,\n  0.8375,\n  0.9375,\n  0.984375,\n  0.9875]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function with query - gallery\n",
    "test_data = np.array([\n",
    "    x[0], x[1], x[2], x[100], x[200]\n",
    "])\n",
    "res = inference_model.predict(finetune_resnet.preprocess_images(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[8.455841, 11.19874, 47.843533, 43.932945]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 1 2 are the same person, 3, 4 are different persons\n",
    "dist = [\n",
    "    np.linalg.norm(res[0] - res[1]),\n",
    "    np.linalg.norm(res[0] - res[2]),\n",
    "    np.linalg.norm(res[0] - res[3]),\n",
    "    np.linalg.norm(res[0] - res[4]),\n",
    "]\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([13.363515, 17.286472, 15.522013, 16.504707],\n ('0067_c5s1_009476_00.jpg',\n  '0067_c5s1_019276_00.jpg',\n  '0067_c5s1_019301_00.jpg',\n  '0077_c4s1_018376_00.jpg',\n  '0095_c4s1_015376_00.jpg'))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on unseen data\n",
    "test_data = np.array([\n",
    "    x[400], x[401], x[402], x[500], x[600]\n",
    "])\n",
    "res = inference_model.predict(finetune_resnet.preprocess_images(test_data))\n",
    "# 0 1 2 are the same person, 3, 4 are different persons\n",
    "dist = [\n",
    "    np.linalg.norm(res[0] - res[1]),\n",
    "    np.linalg.norm(res[0] - res[2]),\n",
    "    np.linalg.norm(res[0] - res[3]),\n",
    "    np.linalg.norm(res[0] - res[4]),\n",
    "]\n",
    "dist, (file_names[400], file_names[401], file_names[402], file_names[500], file_names[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.save_weights(\"../models/full-model-weights.h5\")"
   ]
  }
 ]
}