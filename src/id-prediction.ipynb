{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bittoolsvirtualenvc4ff698609d54025b7f78dd67478b0a8",
   "display_name": "Python 3.7.5 64-bit ('tools': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\tools\\miniconda3\\lib\\site-packages\\h5py\\__init__.py:75: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems\n  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import finetune_resnet\n",
    "import h5py\n",
    "from keras.metrics import sparse_categorical_accuracy\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = h5py.File(\"../Market-1501/market.h5\")\n",
    "x = dataset[\"train_images\"]\n",
    "attributes_target = dataset[\"train_labels\"]\n",
    "file_names = dataset[\"train_images_files\"]\n",
    "ids_encoder = dict()\n",
    "train_ids = np.zeros(len(file_names), dtype=int)\n",
    "i = 0\n",
    "for j, file in enumerate(file_names):\n",
    "    if file[:4] not in ids_encoder:\n",
    "        ids_encoder[file[:4]] = i\n",
    "        i += 1\n",
    "    train_ids[j] = ids_encoder[file[:4]]\n",
    "n_id = len(ids_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((12567,), 751)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids.shape, n_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
    }
   ],
   "source": [
    "_, training_model, inference_model = finetune_resnet.get_models(n_person=n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 128, 64, 3)   0                                            \n__________________________________________________________________________________________________\nresnet50 (Model)                (None, 2048)         23587712    input_1[0][0]                    \n__________________________________________________________________________________________________\nattributes (Dense)              (None, 27)           55323       resnet50[1][0]                   \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 512)          1049088     resnet50[1][0]                   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 27)           756         attributes[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 27)           0           attributes[0][0]                 \n                                                                 dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nimage_features (Concatenate)    (None, 539)          0           multiply_1[0][0]                 \n                                                                 dropout_1[0][0]                  \n__________________________________________________________________________________________________\nids (Dense)                     (None, 751)          405540      image_features[0][0]             \n==================================================================================================\nTotal params: 25,100,467\nTrainable params: 25,046,323\nNon-trainable params: 54,144\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "# sparse_top_k_categorical_accuracy\n",
    "\n",
    "lam = 0.9\n",
    "def attr_loss(y_true, y_pred):\n",
    "    return lam * finetune_resnet.market_attribute_accuracy(y_true, y_pred)\n",
    "def id_loss(y_true, y_pred):\n",
    "    return (1 - lam) * sparse_categorical_accuracy(y_true, y_pred)\n",
    "# optim -> SGD\n",
    "optim = SGD()\n",
    "training_model.compile(\"adam\", loss=[\"binary_crossentropy\", \"sparse_categorical_crossentropy\"], metrics={\"attributes\":[finetune_resnet.market_attribute_accuracy], \"ids\":[sparse_categorical_accuracy]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((1, 27), (1, 751))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes, categorical_id = training_model.predict(finetune_resnet.preprocess_images(x[:1]))\n",
    "attributes.shape, categorical_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 539)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_embedding = inference_model.predict(finetune_resnet.preprocess_images(x[:1]))\n",
    "id_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING:tensorflow:From C:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nTrain on 11310 samples, validate on 1257 samples\nEpoch 8/20\n11310/11310 [==============================] - 2002s 177ms/step - loss: 0.4467 - attributes_loss: 0.1129 - ids_loss: 0.3338 - attributes_market_attribute_accuracy: 0.9154 - ids_sparse_categorical_accuracy: 0.9119 - val_loss: 13.6304 - val_attributes_loss: 0.2702 - val_ids_loss: 13.3602 - val_attributes_market_attribute_accuracy: 0.8211 - val_ids_sparse_categorical_accuracy: 7.9554e-04\nEpoch 9/20\n11310/11310 [==============================] - 1935s 171ms/step - loss: 0.3395 - attributes_loss: 0.1015 - ids_loss: 0.2380 - attributes_market_attribute_accuracy: 0.9237 - ids_sparse_categorical_accuracy: 0.9348 - val_loss: 14.7314 - val_attributes_loss: 0.2674 - val_ids_loss: 14.4639 - val_attributes_market_attribute_accuracy: 0.8277 - val_ids_sparse_categorical_accuracy: 0.0032\nEpoch 10/20\n11310/11310 [==============================] - 1947s 172ms/step - loss: 0.2688 - attributes_loss: 0.0905 - ids_loss: 0.1783 - attributes_market_attribute_accuracy: 0.9323 - ids_sparse_categorical_accuracy: 0.9509 - val_loss: 15.1948 - val_attributes_loss: 0.3014 - val_ids_loss: 14.8934 - val_attributes_market_attribute_accuracy: 0.8186 - val_ids_sparse_categorical_accuracy: 0.0024\nEpoch 11/20\n11310/11310 [==============================] - 1935s 171ms/step - loss: 0.2320 - attributes_loss: 0.0814 - ids_loss: 0.1506 - attributes_market_attribute_accuracy: 0.9387 - ids_sparse_categorical_accuracy: 0.9592 - val_loss: 15.3826 - val_attributes_loss: 0.2731 - val_ids_loss: 15.1095 - val_attributes_market_attribute_accuracy: 0.8278 - val_ids_sparse_categorical_accuracy: 0.0016\nEpoch 12/20\n11310/11310 [==============================] - 1940s 171ms/step - loss: 0.2126 - attributes_loss: 0.0757 - ids_loss: 0.1370 - attributes_market_attribute_accuracy: 0.9431 - ids_sparse_categorical_accuracy: 0.9594 - val_loss: 15.5982 - val_attributes_loss: 0.2981 - val_ids_loss: 15.3000 - val_attributes_market_attribute_accuracy: 0.8289 - val_ids_sparse_categorical_accuracy: 0.0024\nEpoch 13/20\n11310/11310 [==============================] - 1979s 175ms/step - loss: 0.1848 - attributes_loss: 0.0694 - ids_loss: 0.1153 - attributes_market_attribute_accuracy: 0.9476 - ids_sparse_categorical_accuracy: 0.9682 - val_loss: 15.8236 - val_attributes_loss: 0.2918 - val_ids_loss: 15.5319 - val_attributes_market_attribute_accuracy: 0.8281 - val_ids_sparse_categorical_accuracy: 0.0016\nEpoch 14/20\n11310/11310 [==============================] - 1958s 173ms/step - loss: 0.1643 - attributes_loss: 0.0622 - ids_loss: 0.1021 - attributes_market_attribute_accuracy: 0.9532 - ids_sparse_categorical_accuracy: 0.9733 - val_loss: 15.9403 - val_attributes_loss: 0.3154 - val_ids_loss: 15.6249 - val_attributes_market_attribute_accuracy: 0.8233 - val_ids_sparse_categorical_accuracy: 0.0016\nEpoch 15/20\n11310/11310 [==============================] - 1965s 174ms/step - loss: 0.1551 - attributes_loss: 0.0573 - ids_loss: 0.0977 - attributes_market_attribute_accuracy: 0.9559 - ids_sparse_categorical_accuracy: 0.9731 - val_loss: 16.0198 - val_attributes_loss: 0.2977 - val_ids_loss: 15.7221 - val_attributes_market_attribute_accuracy: 0.8287 - val_ids_sparse_categorical_accuracy: 0.0016\nEpoch 16/20\n11310/11310 [==============================] - 1910s 169ms/step - loss: 0.1222 - attributes_loss: 0.0503 - ids_loss: 0.0719 - attributes_market_attribute_accuracy: 0.9611 - ids_sparse_categorical_accuracy: 0.9799 - val_loss: 15.9868 - val_attributes_loss: 0.2988 - val_ids_loss: 15.6880 - val_attributes_market_attribute_accuracy: 0.8338 - val_ids_sparse_categorical_accuracy: 0.0032\nEpoch 17/20\n  128/11310 [..............................] - ETA: 30:28 - loss: 0.1674 - attributes_loss: 0.0480 - ids_loss: 0.1194 - attributes_market_attribute_accuracy: 0.9563 - ids_sparse_categorical_accuracy: 0.9688"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-06eae111aa0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m )\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_model.load_weights(\"../models/full-model-weights-14.37.h5\")\n",
    "cb = [\n",
    "    ModelCheckpoint(\"../models/full-model-weights-{epoch:02d}.h5\", save_weights_only=True),\n",
    "    EarlyStopping(monitor=\"loss\")\n",
    "]\n",
    "\n",
    "# n_samples = 400\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = training_model.fit(\n",
    "    x=finetune_resnet.preprocess_images(np.array(x)),\n",
    "    y=[finetune_resnet.preprocess_labels(np.array(attributes_target)), train_ids],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    callbacks=cb,\n",
    "    initial_epoch=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6cd13d6a221b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function with query - gallery\n",
    "test_data = np.array([\n",
    "    x[0], x[1], x[2], x[100], x[200]\n",
    "])\n",
    "res = inference_model.predict(finetune_resnet.preprocess_images(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[20.43938, 20.798864, 41.726013, 39.351517]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 1 2 are the same person, 3, 4 are different persons\n",
    "dist = [\n",
    "    np.linalg.norm(res[0] - res[1]),\n",
    "    np.linalg.norm(res[0] - res[2]),\n",
    "    np.linalg.norm(res[0] - res[3]),\n",
    "    np.linalg.norm(res[0] - res[4]),\n",
    "]\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([23.436071, 21.682852, 33.515865, 40.13437],\n ('0067_c5s1_009476_00.jpg',\n  '0067_c5s1_019276_00.jpg',\n  '0067_c5s1_019301_00.jpg',\n  '0077_c4s1_018376_00.jpg',\n  '0095_c4s1_015376_00.jpg'))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on unseen data\n",
    "test_data = np.array([\n",
    "    x[400], x[401], x[402], x[500], x[600]\n",
    "])\n",
    "res = inference_model.predict(finetune_resnet.preprocess_images(test_data))\n",
    "# 0 1 2 are the same person, 3, 4 are different persons\n",
    "dist = [\n",
    "    np.linalg.norm(res[0] - res[1]),\n",
    "    np.linalg.norm(res[0] - res[2]),\n",
    "    np.linalg.norm(res[0] - res[3]),\n",
    "    np.linalg.norm(res[0] - res[4]),\n",
    "]\n",
    "dist, (file_names[400], file_names[401], file_names[402], file_names[500], file_names[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.save_weights(\"../models/full-model-weights.h5\")"
   ]
  }
 ]
}